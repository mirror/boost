<?xml version="1.0" standalone="yes"?>
<!DOCTYPE library PUBLIC "-//Boost//DTD BoostBook XML V1.0//EN"
     "http://www.boost.org/tools/boostbook/dtd/boostbook.dtd"
[
    <!ENTITY % entities SYSTEM "program_options.ent" >
    %entities;
]>
<section id="program_options.howto">

  <title>Howto</title>

  <para>This section describes how the library can be used in specific situations.</para>

  <section>
    <title>Unicode support</title>

    <para>To use the library with Unicode, you'd need to:
      <itemizedlist>
        <listitem>
          <para>Use Unicode-aware parsers for unicode input</para>
        </listitem>
        <listitem>
          <para>Require unicode support for options which need it</para>
        </listitem>
      </itemizedlist>
    </para>

    <para>Most of the parsers have unicode versions. For example, the
      &parse_command_line; function has an overload which takes
      <code>wchar_t</code> strings, instead of ordinary <code>char</code>.
    </para>

    <para>Even if some of the parsers are Unicode-aware, it does not mean you
    need to change definition of all the options. In fact, for many options,
    like integer ones, it makes no sense. But to makes use of Unicode, you'd
    need <emphasis>some</emphasis> Unicode-aware options. They are different
    from ordinary option is
    that they accept <code>wstring</code> input, and process it using wide
    character streams. Creating an Unicode-aware option is easy, just use the
    the <code>wvalue</code> function instead of the regular <code>value</code>.
    </para>

    <para>When ascii parser passes data to ascii option, or unicode parser
      passes data to unicode option, the data is not changed at all. So, ascii
      option will see string in local 8 bit encoding, and unicode option will
      see whatever string was passes as unicode input.
    </para>

    <para>The interesting question is what happens when unicode data is passed
      to ascii option, and vice versa. The library perform automatic
      conversion from Unicode to local 8 bit encoding. For example, if command
      line is always ascii, but you use <code>wstring</code> options, then the
      ascii input will be converted into unicode.     
    </para>

    <para>To perform the conversion, library uses the<code>codecvt&lt;wchar_t,
    char&gt;</code> locale facet from the global locale. This means that if
    you want to work with string which use local 8 bit encoding (as opposed to
    7 bit ascii subset),  your application should start with:
      <programlisting>
locale::global(locale(""));
      </programlisting>
      which would set up the conversion facet according to user's selected
      locale. 
    </para>

    <para>It's wise to check the status of C++ locale support on your
      implementation, though. The quick test involves three steps:
      <orderedlist>
        <listitem>
          <para>Go the the "test" directory and built the "test_convert" binary.</para>
        </listitem>
        <listitem>
          <para>Set some non-ascii locale in the environemt. On Linux, one can
          run, for example: <screen>
$ export LC_CTYPE=ru_RU.KOI8-R
</screen>
          </para>
        </listitem>
        <listitem>
          <para>Run the "test_convert" binary passing it as parameter
          arbitrary non-ascii string in selected encoding. If you see a list
          of Unicode codepoints, everything's OK. Otherwise, locale support on
          your system might be broken.</para>
        </listitem>
      </orderedlist>
    </para>

    </section>

</section>

<!--
     Local Variables:
     mode: xml
     sgml-indent-data: t     
     sgml-parent-document: ("program_options.xml" "section")
     sgml-set-face: t
     End:
-->
